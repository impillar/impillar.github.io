---
title: "Making Them Ask and Answer: Jailbreaking Large Language Models in Few Queries via Disguise and Reconstruction"
collection: publications
permalink: /publication/2024-08-14-USENIX-DRA
excerpt: 'It is a work of jailbreaking LLM by exploiting inherit vulnerabilites during safty alignment' 
date: 2024-08-14
venue: 'Proceedings of the 33rd USENIX Security Symposium (USENIX Sec)'
author: "Tong Liu, Ying Jie, Zhe Zhao, Yinpeng Dong, Guozhu Meng, â€‹and Kai Chen"
address: "PHILADELPHIA, PA, USA"
year: 2024
# paperurl: 'http://impillar.github.io/files/usenix2023aliasbackdoor.pdf'
# bib: 'http://impillar.github.io/files/usenix2023aliasbackdoor.md'
citation: ''
remark: "(To appear)"
--
